<!DOCTYPE html>
<html>
	<head>
		<title>Gyuhak Kim</title>
		<!-- link to main stylesheet -->
		<link rel="stylesheet" type="text/css" href="/css/main.css">
	</head>
	<body>
		<nav>
			<ul>
        		<li><a href="mailto:gkim87@uic.edu">Email</a></li>
        		<li><a href="https://github.com/k-gyuhak">Github</a></li>
			<li><a href="https://scholar.google.com/citations?hl=en&user=EguoUcYAAAAJ">Google Scholar</a></li>
				<!-- <li><a href="https://github.com/seoyeon-p/seoyeon-p.github.io/blob/main/cv.pdf">CV</a></li> -->
				<!-- <li><a href="https://www.linkedin.com/in/seoyeonp9/">LinkedIn</a></li> -->
			</ul>
		
		</nav>
		<div class="container">
    		<div class="blurb">
        		<h1></h1>
				<!-- <img src = "IMG_3822.jpeg" height="750" width="1000" object-fit="cover"  style="vertical-align:middle;margin:0px 50px"> -->
				<img src = "IMG_3822.jpeg" height="217.7" width="175" object-fit="cover" style="float:left;padding: 10px" CLEAR=ALL>
				<p>
					I am a PhD student at University of Illnois at Chicago (UIC). My advisor is 
					<a href='https://www.cs.uic.edu/~liub/'>
						<font color='black'>
						<u>Bing Liu</u>
						</font>
					</a>. 
					I am interested in continual learning and out-of-distribution detection. I study conitnual learning and mainly try to construct a principled solution to class incrementl learning. In the beginning of reserach, I also worked on task incremental learning. Prior to studying at UIC, I obtained BA in economics and statistics (double major) from Washington University in Saint Louis (WashU), and obtained MS in mathematics from New York University (NYU).
				</p>
    		</div><!-- /.blurb -->
			<!-- <clear> -->
			<p style="clear:both;">

    		<div class="blurb">	
			<h3> Papers </h3>
			<dl>
				<dt>
					<span>&#8226;</span>
					A Theoretical Study on Solving Continual Learning.
					<b>Gyuhak Kim</b><sup>*</sup>, Changnan Xiao<sup>*</sup>, Tatsuya Konishi, Zixuan Ke, Bing Liu, (* equal contribution).
					NeurIPS 2022.
					<a href=""><font color="black"><u>link</u></font></a>
				</dt>
				<!-- <br> -->
				
				<dt>
					<span>&#8226;</span>
					A Multi-Head Model for Continual Learning via Out-of-Distribution Replay.
					<b>Gyuhak Kim</b>, Zixuan Ke, Bing Liu.
					CoLLAs 2022.
					<a href="https://arxiv.org/pdf/2208.09734.pdf"><font color="black"><u>link</u></font></a>
				</dt>
				<!-- <br> -->
				
				<dt>
					<span>&#8226;</span>
					Continual Learning Based on OOD Detection and Task Masking.
					<b>Gyuhak Kim</b>, Sepideh Esmaeilpour, Changnan Xiao, Bing Liu.
					CVPR Workshops 2022.
					<a href="https://arxiv.org/pdf/2203.09450.pdf"><font color="black"><u>link</u></font></a>
				</dt>
				<!-- <br> -->

				<dt>
					<span>&#8226;</span>
					Partially Relaxed Masks for Knowledge Transfer Without Forgetting in Continual Learning.
					Tatsuya Konishi, Mori Kurokawa, Chihiro Ono, Zixuan Ke, <b>Gyuhak Kim</b>, Bing Liu.
					PAKDD 2022.
					<a href="https://link.springer.com/chapter/10.1007/978-3-031-05933-9_29"><font color="black"><u>link</u></font></a>
				</dt>
				<!-- <br> -->

				<dt>
					<span>&#8226;</span>
					Continual Learning Using Pseudo-Replay via Latent Space Sampling.
					<b>Gyuhak Kim</b>, Sepideh Esmaeilpour, Zixuan Ke, Tatsuya Konishi, Bing Liu.
					Preprint (2021).
					<a href="https://openreview.net/pdf?id=nMo44IjBHX5"><font color="black"><u>link</u></font></a>
				</dt>
				<!-- <br> -->

				<dt>
					<span>&#8226;</span>
					Continual Learning via Principal Components Projection.
					<b>Gyuhak Kim</b> and Bing Liu.
					Preprint (2019).
					<a href="https://openreview.net/pdf?id=SkxlElBYDS"><font color="black"><u>link</u></font></a>
				</dt>
				<!-- <br> -->

			</div><!-- /.blurb -->	
		</div><!-- /.container -->
		<footer>
			<ul>Last Updated: 10/10/2022</ul>
    	</footer>
	</body>
</html>
